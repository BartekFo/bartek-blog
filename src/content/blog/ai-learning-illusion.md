---
title: "The Trap of AI Illusion in Learning"
excerpt: "Why relying too heavily on AI tools can create a dangerous illusion of understanding. A personal reflection on the balance between leveraging AI for productivity and maintaining genuine skill development in unfamiliar territories."
publishDate: "2025-09-23"
tags:
  - AI
  - Learning
  - Developer Growth
  - Productivity
  - Backend Development
  - Skill Development
seo:
  image:
    src: "/ai-learning-illusion.png"
    alt: "A developer looking at code on a screen with a subtle AI overlay, representing the balance between human understanding and AI assistance."
---

It's been a while since my last blog post. The holidays came and went, leading to a small break that turned into a much longer one. This break taught me a few things.

It showed me how **difficult it is to build a consistent habit** and how quickly it can disappear once you step away from it. I also realized that writing valuable articles on a weekly basis is too frequent and hard to maintain alongside my daily responsibilities.

Because of this, I plan to return but with a new goal: **to write once a month**. This will make it much easier for me to choose topics I'm genuinely passionate about, rather than just creating content for the sake of writing, like a text-generating AI.

So, what do I want to talk about today? **The trap of the illusion that AI creates for us.**

## The DHH Discovery

Recently, I was listening to a [Lex Fridman podcast featuring **DHH**](https://www.youtube.com/watch?v=vagyIcmIGOQ)â€”the well-known programmer and creator of the Ruby on Rails framework. I only recently became interested in him when I found time to work on my computer. I replaced a few components, and when choosing an operating system, I realized that nothing was holding me back from Windows. In fact, it was discouraging me from working on side projects and coding.

So, it was time to switch to Linux and choose the right distro. It was a challenge, and I ended up trying a few options. I eventually stumbled upon [**Omarchy**](https://omarchy.org/) and immediately fell in love with it. It provided the ergonomics and ready-made configuration I so desperately needed. As you might expect, it was created by the very DHH I mentioned earlier. So I started checking out his other projects and opinions. That's how I found this podcast (and you might be wondering if this story was necessary for an article about AI. It wasn't, but I want to return to topics related to Linux, ergonomics, and Omarchy in the near future, so consider this a little teaser).

The podcast covered many interesting things, but one statement in particular caught my attention: **DHH doesn't use tools like Cursor or Windsurf for coding**. The first thought that might come to mind is, "He's probably an AI skeptic. I've heard this many times before. No thanks, I have a different opinion." But wait before you close this article!

There's something entirely different to this perspective, and that's what intrigued me. DHH doesn't use these tools not because he doesn't see the value and potential of AI, but because he caught himself asking the same question over and over again: **how to correctly write a loop in Bash** while creating Omarchy.

## My Own Reality Check

This stuck with me, and the next day when I sat down to work, I started paying more attention to what I was asking the AI and how repetitive my requests were. The results surprised me.

For **frontend**, which is my main specialization, I was using AI for repetitive tasks that I already understood well. I had simply written so much similar code that I preferred to have the AI generate it faster.

However, the situation was completely different with **backend**, which I've been getting into lately and want to develop skills in just as much as frontend. Because of this, I'm taking on more backend tasks and diving deeper into architecture. There, my use of AI was more like trying to find a light switch in the dark in a stranger's apartment. You know it should be there, but you just can't find it.

I thought that since I had been working on these tasks for a while, I understood the folder structure, concepts, and architecture well. But when I reviewed my AI queries, I realized how wrong I was. Instead of generating things I already knew, it turned out I was asking the AI **where to find elements X or Y**. While this is understandable in the first few days or weeks on a project, after a longer period of time, you should know this, but I didn't.

## The Learning Trap

It turned out I was using AI so heavily to solve problems that **I never learned to navigate the folder structure and connect patterns fluently on my own**. I want to emphasize that I'm talking about something different from "vibe coding" and throwing out prompts like "Create feature X" and then just checking if it works before making a pull request.

I was actively analyzing the code, pointing out places for improvements, and making sure the quality was good. However, this didn't make me feel comfortable with the code that I hadn't written. I didn't feel like I knew the things I was creating inside and out, and every time I came back to them, I had to put in the same amount of energy to understand what was going on.

When I wrote my last article about blog onboarding, it was based on a presentation I gave at work. At the end, one of my colleagues asked about this very danger: **whether generated code feels like it's "not ours"** and whether we have to focus more when returning to places we were just in.

At the time, I didn't fully see it. I was looking at it from the perspective of a familiar repository I'd been working in for a long time and frontend technologies I know well. The situation, however, is dramatically different when you step outside your daily competencies and try to grow in new areas.

## The Illusion Revealed

It's very easy to fall into the illusion that you understand what's happening because you know the language and concepts. But when you're not writing the code yourself, not changing files, and not analyzing them in depth, **your learning is at risk**. At the end of the day, you're not gaining knowledge; you're standing still or even going backward because you fall into the illusion that with AI, you can do anything, and that's simply not true.

This translates to a similar feeling you get when watching various online courses. There's a reason why people strongly emphasize that when you start your programming journey, you need to **start writing code and creating your own projects** to truly begin to understand.

When we watch someone in a video solve a problem, we think we get it and will be able to write the same thing ourselves in a minute. After all, we know what `array.filter` does, and it's not like we're out of control and the AI is doing whatever it wants. It turns out, however, that we're not quite learning it. It's just an illusion that artificial intelligence gives us, using the same programming language as my frontend, for example.

## Finding the Balance

That's why I encourage everyone to pay attention and see if they're asking the AI to generate a loop for the tenth time or asking where to find the code that gets data from the database in a repository.

**When working with code you know well**, take advantage of the fact that AI can generate it faster than you can write it. If you need to create the fifteenth empty state in an application or write a React Query hook for an endpoint, don't be afraid to speed up your work.

**But when you want to learn something new and grow**, write those things yourself. Throw the AI in a separate tab, discuss the solution's assumptions, or ask for advice, but don't generate everything and remain just a reviewer, because otherwise, you won't learn a thing.
